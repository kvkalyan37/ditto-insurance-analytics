# ============================================
# Multi-stage Dockerfile for API Service
# Optimized for minimal image size using Alpine
# ============================================

# Stage 1: Build dependencies
FROM python:3.11-alpine as builder

WORKDIR /build

# Install build dependencies for compiling Python packages
# Note: musl-dev, gcc, g++ needed for pandas/numpy compilation
RUN apk add --no-cache \
    gcc \
    g++ \
    musl-dev \
    linux-headers \
    libffi-dev \
    && rm -rf /var/cache/apk/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Stage 2: Runtime image (Alpine - minimal)
FROM python:3.11-alpine

WORKDIR /app

# Install only runtime dependencies (no build tools)
# libstdc++ needed for pandas/numpy runtime
RUN apk add --no-cache \
    libstdc++ \
    && rm -rf /var/cache/apk/*

# Copy only installed packages from builder
COPY --from=builder /root/.local /root/.local

# Make sure scripts in .local are usable
ENV PATH=/root/.local/bin:$PATH

# Copy only application code (minimal)
COPY main.py .

# Create data directory (data provided via volume mount)
RUN mkdir -p /app/data

# Note: Data file (ditto_insurance_data.csv) is NOT copied here
# Reason: The CSV file is generated by the scraper and is large/changes frequently
# 
# Data will be provided via:
# 1. Volume mount in Kubernetes (from PVC) - recommended for production
# 2. Or included during scheduled builds (scheduled-update.yml copies it before build)
# 3. Or the app can work without it initially (will show "no data" until mounted)
#
# This allows the Dockerfile to build successfully even without the data file

# Expose port
EXPOSE 8000

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

